{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d25315b2",
   "metadata": {},
   "source": [
    "# **Data Ingestion using Azure Databricks** #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e91b1c",
   "metadata": {},
   "source": [
    "## **1. Create Event Hub from Event Hub Namespace** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c53f1f",
   "metadata": {},
   "source": [
    "## **2. Create Cluster in Databricks workspace** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2967627c",
   "metadata": {},
   "source": [
    "- Azure Resource Group --> Azure Databricks Service --> Launch Workspace --> Compute --> Create with personal compute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca9ed4b",
   "metadata": {},
   "source": [
    "## **3. Install Event Hub Libraries in Databricks Cluster** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f9002",
   "metadata": {},
   "source": [
    "- By default the python library for Event Hub is not supported and built in Databricks cluster. Install it from external package (Library)\n",
    "- Open Databricks cluster --> Libraries --> Install new --> PyPI --> copy-paste package name along with version from the external source ([source](https://pypi.org/project/azure-eventhub/)) --> Install\n",
    "- **Best practice: Restart the cluster after installing the external library to use it without any issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f681c46",
   "metadata": {},
   "source": [
    "## **4. Create sample event using Databricks notebook and sent to Event Hub** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd736066",
   "metadata": {},
   "source": [
    "### **4.1. Create notebook in Databricks workspace and attach target cluster to it** ###\n",
    "- Workspace --> Create --> Notebook --> Connect --> Cluster name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b295e9",
   "metadata": {},
   "source": [
    "### **4.2. Create and send sample Event to Event Hub using Databricks notebook** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c9ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Event Hub Libraries\n",
    "from azure.eventhub import  EventHubProducerClient, EventData\n",
    "import json\n",
    "\n",
    "# Event Hub Configuration\n",
    "EVENT_HUB_CONNECTION_STRING = \"connection-string-key-from-keyVault\"\n",
    "EVENT_HUB_NAME = \"eventhub-name\"\n",
    "\n",
    "# Initialize the Event Hub producer\n",
    "producer = EventHubProducerClient.from_connection_string(conn_str=EVENT_HUB_CONNECTION_STRING, eventhub_name=EVENT_HUB_NAME)\n",
    "\n",
    "# Function to send events to Event Hub\n",
    "def send_event(event):\n",
    "    event_data_batch =producer.create_batch()\n",
    "    event_data_batch.add(EventData(json.dumps(event)))\n",
    "    producer.send_batch(event_data_batch)\n",
    "\n",
    "# Sample JSON event\n",
    "event = {\n",
    "    \"event_id\": 111,\n",
    "    \"event_name\": \"Test Event\",\n",
    "}  \n",
    "\n",
    "# Send the Event\n",
    "send_event(event)\n",
    "\n",
    "# Close the producer\n",
    "producer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfb8ed1",
   "metadata": {},
   "source": [
    "## **5. Configure Key vault Secrets in Databricks** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1c04ab",
   "metadata": {},
   "source": [
    "### **5.1. Create Key Vault SECRET SCOPE** ###\n",
    "- To establish a connection between **Databricks target workspace** and **Azure Key Vault**, we need to create **Secret scope** in the Databricks workspace based on the official Azure Databricks documentation ([Secret management](https://learn.microsoft.com/en-us/azure/databricks/security/secrets/))\n",
    "- A **secret scope** is collection of secrets identified by a name. Databricks recommends aligning secret scopes to roles or applications rather than individuals. There are two types of secret scope:\n",
    "    - **Azure Key Vault-backed:** You can reference secrets stored in an Azure Key Vault using Azure Key Vault-backed secret scopes. Azure Key Vault-backed secret scope is a read-only interface to the Key Vault. You must manage secrets in Azure Key Vault-backed secret scopes in Azure.\n",
    "    - **Databricks-backed:** A Databricks-backed secret scope is stored in an encrypted database owned and managed by Azure Databricks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a396ba",
   "metadata": {},
   "source": [
    "### **5.2. Update connection string to directly get the key from Azure Key Vault** ###\n",
    "- When you run the notebook, it fails with denied access error message. To solve the issue, assign **\"Key vault Secrets user\"** role to **AzureDatabricks** service principal.\n",
    "- An **Azure Databricks application service principal** is an **Azure Entra ID (Azure AD)** identity used by applications, pipelines, or automation to authenticate to Azure Databricks without a human user. It enables secure, non-interactive access for CI/CD, jobs, and integrations (e.g., ADF, Fabric, GitHub Actions). Permissions are granted through **Azure RBAC, Databricks workspace roles**, and **Unity Catalog access**, following least-privilege principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8863d7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting secret value from Key Vault\n",
    "eventhub_connection_string = dbutils.secrets.get(scope = \"key-vault-scope-name\", key = \"key-vault-secret-name\")\n",
    "EVENT_HUB_NAME = \"eventhub-name\"\n",
    "\n",
    "# Initialize the Event Hub producer\n",
    "producer = EventHubProducerClient.from_connection_string(conn_str=eventhub_connection_string, eventhub_name=EVENT_HUB_NAME)\n",
    "\n",
    "# Function to send events to Event Hub\n",
    "def send_event(event):\n",
    "    event_data_batch =producer.create_batch()\n",
    "    event_data_batch.add(EventData(json.dumps(event)))\n",
    "    producer.send_batch(event_data_batch)\n",
    "\n",
    "# Sample JSON event\n",
    "event = {\n",
    "    \"event_id\": 333,\n",
    "    \"event_name\": \"Key Vault Test\",\n",
    "}  \n",
    "\n",
    "# Send the Event\n",
    "send_event(event)\n",
    "\n",
    "# Close the producer\n",
    "producer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28bd01",
   "metadata": {},
   "source": [
    "## **6. Weather API Testing** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7823a8",
   "metadata": {},
   "source": [
    "Refer weather API documentation [API Doc](https://www.weatherapi.com/docs/)\n",
    "- **Request URL:** Request to WeatherAPI.com API consists of **base url** and **API method**. You can make both HTTP or HTTPS request.\n",
    "- **Request Parameters:** API Key, Query parameter (q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7864209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Getting secret value from key vault\n",
    "weatherapikey = dbutils.secrets.get(scope = \"key-vault-scope-name\", key = \"API_key-name_from_Key-Vault\")\n",
    "location = \"location-name\"\n",
    "\n",
    "# Base URL from the official documentation\n",
    "base_url = \"http://api.weatherapi.com/v1/\"\n",
    "\n",
    "# Current weather endpoint = f\"{base_url}/API-method\"\n",
    "current_weather_url = f\"{base_url}/current.json\"\n",
    "\n",
    "\n",
    "# Define the parameters for the API request\n",
    "params = {\n",
    "    'key': weatherapikey,\n",
    "    'q': location,\n",
    "}\n",
    "\n",
    "# Make the API request\n",
    "response = requests.get(current_weather_url, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    current_weather = response.json()\n",
    "    print(\"Current weather:\")\n",
    "    print(json.dumps(current_weather, indent=3))\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc17bb9",
   "metadata": {},
   "source": [
    "## **7. Developing complete Code for getting Weather Data** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3fca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Function to handle the API response\n",
    "def handle_response(response):\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "\n",
    "# Function to get current weather and air quality data\n",
    "def get_current_weather(base_url, api_key, location):\n",
    "    current_weather_url = f\"{base_url}/current.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"aqi\": 'yes'\n",
    "    }\n",
    "    response = requests.get(current_weather_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get Forecast data\n",
    "def get_forecast_weather(base_url, api_key, location, days):\n",
    "    forecast_url = f\"{base_url}/forecast.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"days\": days,\n",
    "    }\n",
    "    response = requests.get(forecast_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get alerts\n",
    "def get_alerts(base_url, api_key, location):\n",
    "    alerts_url = f\"{base_url}/alerts.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"alerts\": 'yes'\n",
    "    }\n",
    "    response = requests.get(alerts_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Flatten and merge the data\n",
    "def flatten_data(current_weather, forecast_weather, alerts):\n",
    "    location_data = current_weather.get(\"location\",{})\n",
    "    current = current_weather.get(\"current\",{})\n",
    "    condition = current.get(\"condition\",{})\n",
    "    air_quality = current.get(\"air_quality\",{})\n",
    "    forecast = forecast_weather.get(\"forecast\",{}).get(\"forecastday\",[])\n",
    "    alert_list = alerts.get(\"alerts\",{}).get(\"alert\",[])\n",
    "\n",
    "    flattened_data = {\n",
    "        'name': location_data.get(\"name\"),\n",
    "        'region': location_data.get(\"region\"),\n",
    "        'country': location_data.get(\"country\"),\n",
    "        'lat': location_data.get(\"lat\"),\n",
    "        'lon': location_data.get(\"lon\"),\n",
    "        'localtime': location_data.get(\"localtime\"),\n",
    "        'temp_c': current.get(\"temp_c\"),\n",
    "        'is_day': current.get(\"is_day\"),\n",
    "        'condition_text': condition.get(\"text\"),\n",
    "        'condition_icon': condition.get(\"icon\"),\n",
    "        'wind_kph': current.get(\"wind_kph\"),\n",
    "        'wind_degree': current.get(\"wind_degree\"),\n",
    "        'wind_dir': current.get(\"wind_dir\"),\n",
    "        'pressure_in': current.get(\"pressure_in\"),\n",
    "        'precip_in': current.get(\"precip_in\"),\n",
    "        'humidity': current.get(\"humidity\"),\n",
    "        'cloud': current.get('cloud'),\n",
    "        'feelslike_c': current.get('feelslike_c'),\n",
    "        'uv': current.get('uv'),\n",
    "        'air_quality': {\n",
    "            'co': air_quality.get('co'),\n",
    "            'no2': air_quality.get('no2'),\n",
    "            'o3': air_quality.get('o3'),\n",
    "            'so2': air_quality.get('so2'),\n",
    "            'pm2_5': air_quality.get('pm2_5'),\n",
    "            'pm10': air_quality.get('pm10'),\n",
    "            'us-epa-index': air_quality.get('us-epa-index'),\n",
    "            'gb-defra-index': air_quality.get('gb-defra-index')\n",
    "        },\n",
    "        'alerts': [\n",
    "            {\n",
    "                'headline': alert.get('headline'),\n",
    "                'severity': alert.get('severity'),\n",
    "                'description': alert.get('desc'),\n",
    "                'instruction': alert.get('instruction'),\n",
    "            }\n",
    "            for alert in alert_list\n",
    "        ],\n",
    "        'forecast': [\n",
    "            {\n",
    "                'date': day.get('date'),\n",
    "                'maxtemp_c': day.get('day').get('maxtemp_c'),\n",
    "                'mintemp_c': day.get('day').get('mintemp_c'),\n",
    "                'condition': day.get('day').get('condition').get('text'),\n",
    "                'condition_icon': day.get('day').get('condition').get('text')\n",
    "            }\n",
    "            for day in forecast\n",
    "        ]\n",
    "    }\n",
    "    return flattened_data\n",
    "# Main program\n",
    "def fetch_weather_data():\n",
    "    base_url = \"http://api.weatherapi.com/v1/\"\n",
    "    location = \"Chennai\"\n",
    "    weatherapikey = dbutils.secrets.get(scope = \"<secret-scope>\", key = \"<kv-api-key>\")\n",
    "    \n",
    "    # Get data from API\n",
    "    current_weather = get_current_weather(base_url, weatherapikey, location)\n",
    "    forecast_weather = get_forecast_weather(base_url, weatherapikey, location, 3)\n",
    "    alerts = get_alerts(base_url, weatherapikey, location)\n",
    "    \n",
    "    # Flatten and merge the data\n",
    "    merged_data = flatten_data(current_weather, forecast_weather, alerts)\n",
    "    print(\"Weather Data:\",json.dumps(merged_data, indent=3))\n",
    "\n",
    "# Calling the main program\n",
    "fetch_weather_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dda2d60",
   "metadata": {},
   "source": [
    "## **8. Final Data Ingestion from Databricks to Event Hub** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de87ae9",
   "metadata": {},
   "source": [
    "- Combine step (5.2) and step (7)\n",
    "    - configure Event Hub and Databricks workspace connection string.\n",
    "    - send result to Event Hub as an event instead of printing\n",
    "- Implementation:\n",
    "    - add import event hub library \n",
    "    - add event hub configuration (connection string, event hub name, producer initialization)\n",
    "    - add the function to sent event to event hub\n",
    "    - Modify the code to send the weather data to Event Hub in streaming fashion (not only the latest event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a2e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# ----------\n",
    "# add eventhup library to connect to event hub\n",
    "from azure.eventhub import  EventHubProducerClient, EventData\n",
    "\n",
    "# Getting secret value from Key Vault\n",
    "eventhub_connection_string = dbutils.secrets.get(scope = \"<key-vault-scope-name>\", key = \"<key-vault-secret-name>\")\n",
    "EVENT_HUB_NAME = \"<event hub name>\"\n",
    "\n",
    "# Initialize the Event Hub producer\n",
    "producer = EventHubProducerClient.from_connection_string(conn_str=eventhub_connection_string, eventhub_name=EVENT_HUB_NAME)\n",
    "\n",
    "# Function to send events to Event Hub\n",
    "def send_event(event):\n",
    "    event_data_batch =producer.create_batch()\n",
    "    event_data_batch.add(EventData(json.dumps(event)))\n",
    "    producer.send_batch(event_data_batch)\n",
    "\n",
    "# -----------\n",
    "\n",
    "# Function to handle the API response\n",
    "def handle_response(response):\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "\n",
    "# Function to get current weather and air quality data\n",
    "def get_current_weather(base_url, api_key, location):\n",
    "    current_weather_url = f\"{base_url}/current.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"aqi\": 'yes'\n",
    "    }\n",
    "    response = requests.get(current_weather_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get Forecast data\n",
    "def get_forecast_weather(base_url, api_key, location, days):\n",
    "    forecast_url = f\"{base_url}/forecast.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"days\": days,\n",
    "    }\n",
    "    response = requests.get(forecast_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get alerts\n",
    "def get_alerts(base_url, api_key, location):\n",
    "    alerts_url = f\"{base_url}/alerts.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"alerts\": 'yes'\n",
    "    }\n",
    "    response = requests.get(alerts_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Flatten and merge the data\n",
    "def flatten_data(current_weather, forecast_weather, alerts):\n",
    "    location_data = current_weather.get(\"location\",{})\n",
    "    current = current_weather.get(\"current\",{})\n",
    "    condition = current.get(\"condition\",{})\n",
    "    air_quality = current.get(\"air_quality\",{})\n",
    "    forecast = forecast_weather.get(\"forecast\",{}).get(\"forecastday\",[])\n",
    "    alert_list = alerts.get(\"alerts\",{}).get(\"alert\",[])\n",
    "\n",
    "    flattened_data = {\n",
    "        'name': location_data.get(\"name\"),\n",
    "        'region': location_data.get(\"region\"),\n",
    "        'country': location_data.get(\"country\"),\n",
    "        'lat': location_data.get(\"lat\"),\n",
    "        'lon': location_data.get(\"lon\"),\n",
    "        'localtime': location_data.get(\"localtime\"),\n",
    "        'temp_c': current.get(\"temp_c\"),\n",
    "        'is_day': current.get(\"is_day\"),\n",
    "        'condition_text': condition.get(\"text\"),\n",
    "        'condition_icon': condition.get(\"icon\"),\n",
    "        'wind_kph': current.get(\"wind_kph\"),\n",
    "        'wind_degree': current.get(\"wind_degree\"),\n",
    "        'wind_dir': current.get(\"wind_dir\"),\n",
    "        'pressure_in': current.get(\"pressure_in\"),\n",
    "        'precip_in': current.get(\"precip_in\"),\n",
    "        'humidity': current.get(\"humidity\"),\n",
    "        'cloud': current.get('cloud'),\n",
    "        'feelslike_c': current.get('feelslike_c'),\n",
    "        'uv': current.get('uv'),\n",
    "        'air_quality': {\n",
    "            'co': air_quality.get('co'),\n",
    "            'no2': air_quality.get('no2'),\n",
    "            'o3': air_quality.get('o3'),\n",
    "            'so2': air_quality.get('so2'),\n",
    "            'pm2_5': air_quality.get('pm2_5'),\n",
    "            'pm10': air_quality.get('pm10'),\n",
    "            'us-epa-index': air_quality.get('us-epa-index'),\n",
    "            'gb-defra-index': air_quality.get('gb-defra-index')\n",
    "        },\n",
    "        'alerts': [\n",
    "            {\n",
    "                'headline': alert.get('headline'),\n",
    "                'severity': alert.get('severity'),\n",
    "                'description': alert.get('desc'),\n",
    "                'instruction': alert.get('instruction'),\n",
    "            }\n",
    "            for alert in alert_list\n",
    "        ],\n",
    "        'forecast': [\n",
    "            {\n",
    "                'date': day.get('date'),\n",
    "                'maxtemp_c': day.get('day').get('maxtemp_c'),\n",
    "                'mintemp_c': day.get('day').get('mintemp_c'),\n",
    "                'condition': day.get('day').get('condition').get('text'),\n",
    "                'condition_icon': day.get('day').get('condition').get('text')\n",
    "            }\n",
    "            for day in forecast\n",
    "        ]\n",
    "    }\n",
    "    return flattened_data\n",
    "    \n",
    "# Main program\n",
    "def fetch_weather_data():\n",
    "    base_url = \"http://api.weatherapi.com/v1/\"\n",
    "    location = \"Chennai\"\n",
    "    weatherapikey = dbutils.secrets.get(scope = \"key-vault-scope\", key = \"weatherapikey\")\n",
    "    \n",
    "    # Get data from API\n",
    "    current_weather = get_current_weather(base_url, weatherapikey, location)\n",
    "    forecast_weather = get_forecast_weather(base_url, weatherapikey, location, 3)\n",
    "    alerts = get_alerts(base_url, weatherapikey, location)\n",
    "    \n",
    "    # Flatten and merge the data\n",
    "    merged_data = flatten_data(current_weather, forecast_weather, alerts)\n",
    "    #print(\"Weather Data:\",json.dumps(merged_data, indent=3))\n",
    "\n",
    "    # -------\n",
    "    # Sending the weather data to Event Hub\n",
    "    send_event(merged_data)\n",
    "    # -------\n",
    "\n",
    "# Calling the main program\n",
    "fetch_weather_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec273882",
   "metadata": {},
   "source": [
    "## **Sending the complete weather data to the Event Hub in Streaming fashion** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad16490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# ----------\n",
    "# add eventhup library to connect to event hub\n",
    "from azure.eventhub import  EventHubProducerClient, EventData\n",
    "\n",
    "# Getting secret value from Key Vault\n",
    "eventhub_connection_string = dbutils.secrets.get(scope = \"key-vault-scope-name\", key = \"<Key-Vault-EventHub-conn-str>\")\n",
    "EVENT_HUB_NAME = \"<Event-Hub-Name>\"\n",
    "\n",
    "# Initialize the Event Hub producer\n",
    "producer = EventHubProducerClient.from_connection_string(conn_str=eventhub_connection_string, eventhub_name=EVENT_HUB_NAME)\n",
    "\n",
    "# Function to send events to Event Hub\n",
    "def send_event(event):\n",
    "    event_data_batch =producer.create_batch()\n",
    "    event_data_batch.add(EventData(json.dumps(event)))\n",
    "    producer.send_batch(event_data_batch)\n",
    "\n",
    "# -----------\n",
    "\n",
    "# Function to handle the API response\n",
    "def handle_response(response):\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "\n",
    "# Function to get current weather and air quality data\n",
    "def get_current_weather(base_url, api_key, location):\n",
    "    current_weather_url = f\"{base_url}/current.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"aqi\": 'yes'\n",
    "    }\n",
    "    response = requests.get(current_weather_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get Forecast data\n",
    "def get_forecast_weather(base_url, api_key, location, days):\n",
    "    forecast_url = f\"{base_url}/forecast.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"days\": days,\n",
    "    }\n",
    "    response = requests.get(forecast_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get alerts\n",
    "def get_alerts(base_url, api_key, location):\n",
    "    alerts_url = f\"{base_url}/alerts.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"alerts\": 'yes'\n",
    "    }\n",
    "    response = requests.get(alerts_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Flatten and merge the data\n",
    "def flatten_data(current_weather, forecast_weather, alerts):\n",
    "    location_data = current_weather.get(\"location\",{})\n",
    "    current = current_weather.get(\"current\",{})\n",
    "    condition = current.get(\"condition\",{})\n",
    "    air_quality = current.get(\"air_quality\",{})\n",
    "    forecast = forecast_weather.get(\"forecast\",{}).get(\"forecastday\",[])\n",
    "    alert_list = alerts.get(\"alerts\",{}).get(\"alert\",[])\n",
    "\n",
    "    flattened_data = {\n",
    "        'name': location_data.get(\"name\"),\n",
    "        'region': location_data.get(\"region\"),\n",
    "        'country': location_data.get(\"country\"),\n",
    "        'lat': location_data.get(\"lat\"),\n",
    "        'lon': location_data.get(\"lon\"),\n",
    "        'localtime': location_data.get(\"localtime\"),\n",
    "        'temp_c': current.get(\"temp_c\"),\n",
    "        'is_day': current.get(\"is_day\"),\n",
    "        'condition_text': condition.get(\"text\"),\n",
    "        'condition_icon': condition.get(\"icon\"),\n",
    "        'wind_kph': current.get(\"wind_kph\"),\n",
    "        'wind_degree': current.get(\"wind_degree\"),\n",
    "        'wind_dir': current.get(\"wind_dir\"),\n",
    "        'pressure_in': current.get(\"pressure_in\"),\n",
    "        'precip_in': current.get(\"precip_in\"),\n",
    "        'humidity': current.get(\"humidity\"),\n",
    "        'cloud': current.get('cloud'),\n",
    "        'feelslike_c': current.get('feelslike_c'),\n",
    "        'uv': current.get('uv'),\n",
    "        'air_quality': {\n",
    "            'co': air_quality.get('co'),\n",
    "            'no2': air_quality.get('no2'),\n",
    "            'o3': air_quality.get('o3'),\n",
    "            'so2': air_quality.get('so2'),\n",
    "            'pm2_5': air_quality.get('pm2_5'),\n",
    "            'pm10': air_quality.get('pm10'),\n",
    "            'us-epa-index': air_quality.get('us-epa-index'),\n",
    "            'gb-defra-index': air_quality.get('gb-defra-index')\n",
    "        },\n",
    "        'alerts': [\n",
    "            {\n",
    "                'headline': alert.get('headline'),\n",
    "                'severity': alert.get('severity'),\n",
    "                'description': alert.get('desc'),\n",
    "                'instruction': alert.get('instruction'),\n",
    "            }\n",
    "            for alert in alert_list\n",
    "        ],\n",
    "        'forecast': [\n",
    "            {\n",
    "                'date': day.get('date'),\n",
    "                'maxtemp_c': day.get('day').get('maxtemp_c'),\n",
    "                'mintemp_c': day.get('day').get('mintemp_c'),\n",
    "                'condition': day.get('day').get('condition').get('text'),\n",
    "                'condition_icon': day.get('day').get('condition').get('text')\n",
    "            }\n",
    "            for day in forecast\n",
    "        ]\n",
    "    }\n",
    "    return flattened_data\n",
    "\n",
    "\n",
    "def fetch_weather_data():\n",
    "    base_url = \"http://api.weatherapi.com/v1/\"\n",
    "    location = \"<location>\"\n",
    "    weatherapikey = dbutils.secrets.get(scope = \"<key-Vault-Secret-scope>\", key = \"<Key-Vault-API-Name>\")\n",
    "    \n",
    "    # Get data from API\n",
    "    current_weather = get_current_weather(base_url, weatherapikey, location)\n",
    "    forecast_weather = get_forecast_weather(base_url, weatherapikey, location, 3)\n",
    "    alerts = get_alerts(base_url, weatherapikey, location)\n",
    "    \n",
    "    # Flatten and merge the data\n",
    "    merged_data = flatten_data(current_weather, forecast_weather, alerts)\n",
    "    return merged_data\n",
    "\n",
    "# Main program\n",
    "def process_df(batch_df, batch_id):\n",
    "    try:\n",
    "        # Fetch weather data\n",
    "        weather_data = fetch_weather_data()\n",
    "\n",
    "        # Send weather data (current weather part)\n",
    "        send_event(weather_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending events in batch {batch_id}: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "# Set up a streaming source (for example, rate source for testing purpose)\n",
    "streaming_df = spark.readStream.format(\"rate\").option(\"rowsPerSecond\", 1).load()\n",
    "\n",
    "# Process the data\n",
    "query = streaming_df.writeStream.foreachBatch(process_df).start()\n",
    "\n",
    "query.awaitTermination()\n",
    "\n",
    "# Close the producer after termination\n",
    "producer.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
